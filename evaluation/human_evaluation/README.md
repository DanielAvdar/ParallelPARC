This folder contains all files related to the human evaluation in both the binary classification and multiple-choice task. <br>
See Section 5 -- "Evaluating Humans and LLMs" in the paper. <br>
For the binary task, we evaluate human in zero-shot (looking only at the prompt given to models), and supervised settings (learning from their mistakes). <br>
For the multiple-choice task, we consider the annotators only for the supervised settings and evaluating the results in both Basic and Advanced setups. 